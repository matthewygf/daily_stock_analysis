# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import json
import logging
import re
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List
from json_repair import repair_json

from src.config import get_config

logger = logging.getLogger(__name__)


# è‚¡ç¥¨åç§°æ˜ å°„ï¼ˆå¸¸è§è‚¡ç¥¨ï¼‰
STOCK_NAME_MAP = {
    # === Aè‚¡ ===
    '600519': 'è´µå·èŒ…å°',
    '000001': 'å¹³å®‰é“¶è¡Œ',
    '300750': 'å®å¾·æ—¶ä»£',
    '002594': 'æ¯”äºšè¿ª',
    '600036': 'æ‹›å•†é“¶è¡Œ',
    '601318': 'ä¸­å›½å¹³å®‰',
    '000858': 'äº”ç²®æ¶²',
    '600276': 'æ’ç‘åŒ»è¯',
    '601012': 'éš†åŸºç»¿èƒ½',
    '002475': 'ç«‹è®¯ç²¾å¯†',
    '300059': 'ä¸œæ–¹è´¢å¯Œ',
    '002415': 'æµ·åº·å¨è§†',
    '600900': 'é•¿æ±Ÿç”µåŠ›',
    '601166': 'å…´ä¸šé“¶è¡Œ',
    '600028': 'ä¸­å›½çŸ³åŒ–',

    # === ç¾è‚¡ ===
    'AAPL': 'è‹¹æœ',
    'TSLA': 'ç‰¹æ–¯æ‹‰',
    'MSFT': 'å¾®è½¯',
    'GOOGL': 'è°·æ­ŒA',
    'GOOG': 'è°·æ­ŒC',
    'AMZN': 'äºšé©¬é€Š',
    'NVDA': 'è‹±ä¼Ÿè¾¾',
    'META': 'Meta',
    'AMD': 'AMD',
    'INTC': 'è‹±ç‰¹å°”',
    'BABA': 'é˜¿é‡Œå·´å·´',
    'PDD': 'æ‹¼å¤šå¤š',
    'JD': 'äº¬ä¸œ',
    'BIDU': 'ç™¾åº¦',
    'NIO': 'è”šæ¥',
    'XPEV': 'å°é¹æ±½è½¦',
    'LI': 'ç†æƒ³æ±½è½¦',
    'COIN': 'Coinbase',
    'MSTR': 'MicroStrategy',

    # === æ¸¯è‚¡ (5ä½æ•°å­—) ===
    '00700': 'è…¾è®¯æ§è‚¡',
    '03690': 'ç¾å›¢',
    '01810': 'å°ç±³é›†å›¢',
    '09988': 'é˜¿é‡Œå·´å·´',
    '09618': 'äº¬ä¸œé›†å›¢',
    '09888': 'ç™¾åº¦é›†å›¢',
    '01024': 'å¿«æ‰‹',
    '00981': 'ä¸­èŠ¯å›½é™…',
    '02015': 'ç†æƒ³æ±½è½¦',
    '09868': 'å°é¹æ±½è½¦',
    '00005': 'æ±‡ä¸°æ§è‚¡',
    '01299': 'å‹é‚¦ä¿é™©',
    '00941': 'ä¸­å›½ç§»åŠ¨',
    '00883': 'ä¸­å›½æµ·æ´‹çŸ³æ²¹',
}

# Expanded Risk Dictionary with Market Targeting
TIME_RISK_EVENTS = {
    # --- Global / US Impact (Affects almost everything) ---
    "EARNINGS": {
        "keywords": [
            "è´¢æŠ¥å‘å¸ƒ", "å‘å¸ƒè´¢æŠ¥", "å…¬å¸ƒè´¢æŠ¥", "æŠ«éœ²è´¢æŠ¥", # Action: Publishing
            "ä¸šç»©æš´é›·", "ä¸šç»©ä¸åŠ", "æŒ‡å¼•ä¸‹è°ƒ",             # Action: Bad news
            "å³å°†è´¢æŠ¥", "ä¸´è¿‘è´¢æŠ¥",                         # Action: Timing
            "Earnings Release", "Report Earnings"
        ],
        "reason": "ä¸ªè‚¡ä¸´è¿‘è´¢æŠ¥å‘å¸ƒæˆ–ä¸šç»©æš´é›·ï¼Œå­˜åœ¨éš”å¤œè·³ç©ºé£é™©",
        "target_markets": ["ALL"]
    },

    # Optimized Fed Keywords
    "FED_DECISION": {
        "keywords": [
            "åˆ©ç‡å†³è®®", "è®®æ¯ä¼šè®®", "å³å°†åŠ æ¯", "å³å°†é™æ¯",
            "FOMC Meeting", "Fed Decision"
        ],
        "reason": "ä¸´è¿‘ç¾è”å‚¨åˆ©ç‡å†³è®®ï¼ŒæµåŠ¨æ€§é¢„æœŸæ³¢åŠ¨æå¤§",
        "target_markets": ["US", "HK", "CRYPTO"]
    },
    # --- China Specific (A-Shares / HK Stocks) ---
    "CN_POLICY": {
        "keywords": ["äººè¡Œ", "å¤®è¡Œ", "é™å‡†", "LPR", "MLF", "é€†å›è´­", "ä¸¤ä¼š", "åå››äº”"],
        "reason": "å›½å†…é‡å¤§ä¼šè®®æˆ–ç›‘ç®¡æ”¿ç­–å‘å¸ƒï¼Œæ¿å—è½®åŠ¨é£é™©å¤§",
        "target_markets": ["CN", "HK"]
    },
    
    # --- US Specific (US Stocks) ---
    "US_MACRO": {
        "keywords": ["éå†œ", "ç¾å›½CPI", "ç¾å›½PCE", "ç¾è‚¡è´¢æŠ¥", "å››å·«æ—¥"],
        "reason": "ç¾è‚¡æ ¸å¿ƒå®è§‚æ•°æ®æˆ–äº¤å‰²æ—¥ï¼Œç”±äºä¸è®¾æ¶¨è·Œå¹…ï¼Œæ³¢åŠ¨æé«˜",
        "target_markets": ["US", "HK", "CRYPTO"]
    },
    
    # --- Crypto Specific ---
    "CRYPTO_EVENTS": {
        "keywords": ["å‡åŠ", "SECç›‘ç®¡", "ETFå®¡æ‰¹", "é“¾ä¸Šæ‹¥å µ", "Gasè´¹"],
        "reason": "åŠ å¯†è´§å¸ç‰¹æœ‰è¡Œä¸šäº‹ä»¶ï¼Œå­˜åœ¨æç«¯æ³¢åŠ¨é£é™©",
        "target_markets": ["CRYPTO"]
    },
}

def get_stock_name_multi_source(
    stock_code: str,
    context: Optional[Dict] = None,
    data_manager = None
) -> str:
    """
    å¤šæ¥æºè·å–è‚¡ç¥¨ä¸­æ–‡åç§°

    è·å–ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä»ä¼ å…¥çš„ context ä¸­è·å–ï¼ˆrealtime æ•°æ®ï¼‰
    2. ä»é™æ€æ˜ å°„è¡¨ STOCK_NAME_MAP è·å–
    3. ä» DataFetcherManager è·å–ï¼ˆå„æ•°æ®æºï¼‰
    4. è¿”å›é»˜è®¤åç§°ï¼ˆè‚¡ç¥¨+ä»£ç ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        context: åˆ†æä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        data_manager: DataFetcherManager å®ä¾‹ï¼ˆå¯é€‰ï¼‰

    Returns:
        è‚¡ç¥¨ä¸­æ–‡åç§°
    """
    # 1. ä»ä¸Šä¸‹æ–‡è·å–ï¼ˆå®æ—¶è¡Œæƒ…æ•°æ®ï¼‰
    if context:
        # ä¼˜å…ˆä» stock_name å­—æ®µè·å–
        if context.get('stock_name'):
            name = context['stock_name']
            if name and not name.startswith('è‚¡ç¥¨'):
                return name

        # å…¶æ¬¡ä» realtime æ•°æ®è·å–
        if 'realtime' in context and context['realtime'].get('name'):
            return context['realtime']['name']

    # 2. ä»é™æ€æ˜ å°„è¡¨è·å–
    if stock_code in STOCK_NAME_MAP:
        return STOCK_NAME_MAP[stock_code]

    # 3. ä»æ•°æ®æºè·å–
    if data_manager is None:
        try:
            from data_provider.base import DataFetcherManager
            data_manager = DataFetcherManager()
        except Exception as e:
            logger.debug(f"æ— æ³•åˆå§‹åŒ– DataFetcherManager: {e}")

    if data_manager:
        try:
            name = data_manager.get_stock_name(stock_code)
            if name:
                # æ›´æ–°ç¼“å­˜
                STOCK_NAME_MAP[stock_code] = name
                return name
        except Exception as e:
            logger.debug(f"ä»æ•°æ®æºè·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")

    # 4. è¿”å›é»˜è®¤åç§°
    return f'è‚¡ç¥¨{stock_code}'


@dataclass
class AnalysisResult:
    """
    AI åˆ†æç»“æœæ•°æ®ç±» - å†³ç­–ä»ªè¡¨ç›˜ç‰ˆ

    å°è£… Gemini è¿”å›çš„åˆ†æç»“æœï¼ŒåŒ…å«å†³ç­–ä»ªè¡¨ç›˜å’Œè¯¦ç»†åˆ†æ
    """
    code: str
    name: str

    # ========== æ ¸å¿ƒæŒ‡æ ‡ ==========
    sentiment_score: int  # ç»¼åˆè¯„åˆ† 0-100 (>70å¼ºçƒˆçœ‹å¤š, >60çœ‹å¤š, 40-60éœ‡è¡, <40çœ‹ç©º)
    trend_prediction: str  # è¶‹åŠ¿é¢„æµ‹ï¼šå¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè®®ï¼šä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›
    decision_type: str = "hold"  # å†³ç­–ç±»å‹ï¼šbuy/hold/sellï¼ˆç”¨äºç»Ÿè®¡ï¼‰
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½

    # ========== å†³ç­–ä»ªè¡¨ç›˜ (æ–°å¢) ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„å†³ç­–ä»ªè¡¨ç›˜æ•°æ®

    # ========== èµ°åŠ¿åˆ†æ ==========
    trend_analysis: str = ""  # èµ°åŠ¿å½¢æ€åˆ†æï¼ˆæ”¯æ’‘ä½ã€å‹åŠ›ä½ã€è¶‹åŠ¿çº¿ç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰

    # ========== æŠ€æœ¯é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æ
    ma_analysis: str = ""  # å‡çº¿åˆ†æï¼ˆå¤šå¤´/ç©ºå¤´æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ï¼Œä¸»åŠ›åŠ¨å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kçº¿å½¢æ€åˆ†æ

    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç»¼åˆåˆ†æ
    sector_position: str = ""  # æ¿å—åœ°ä½å’Œè¡Œä¸šè¶‹åŠ¿
    company_highlights: str = ""  # å…¬å¸äº®ç‚¹/é£é™©ç‚¹

    # ========== æƒ…ç»ªé¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°é—»/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚åœºæƒ…ç»ªåˆ†æ
    hot_topics: str = ""  # ç›¸å…³çƒ­ç‚¹è¯é¢˜

    # ========== ç»¼åˆåˆ†æ ==========
    analysis_summary: str = ""  # ç»¼åˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹ç‚¹ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
    risk_warning: str = ""  # é£é™©æç¤º
    buy_reason: str = ""  # ä¹°å…¥/å–å‡ºç†ç”±

    # ========== å…ƒæ•°æ® ==========
    market_snapshot: Optional[Dict[str, Any]] = None  # å½“æ—¥è¡Œæƒ…å¿«ç…§ï¼ˆå±•ç¤ºç”¨ï¼‰
    raw_response: Optional[str] = None  # åŸå§‹å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦æ‰§è¡Œäº†è”ç½‘æœç´¢
    data_sources: str = ""  # æ•°æ®æ¥æºè¯´æ˜
    success: bool = True
    error_message: Optional[str] = None

    # ========== ä»·æ ¼æ•°æ®ï¼ˆåˆ†ææ—¶å¿«ç…§ï¼‰==========
    current_price: Optional[float] = None  # åˆ†ææ—¶çš„è‚¡ä»·
    change_pct: Optional[float] = None     # åˆ†ææ—¶çš„æ¶¨è·Œå¹…(%)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'decision_type': self.decision_type,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,  # å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'market_snapshot': self.market_snapshot,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
            'current_price': self.current_price,
            'change_pct': self.change_pct,
        }

    def get_core_conclusion(self) -> str:
        """è·å–æ ¸å¿ƒç»“è®ºï¼ˆä¸€å¥è¯ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary

    def get_position_advice(self, has_position: bool = False) -> str:
        """è·å–æŒä»“å»ºè®®"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice

    def get_sniper_points(self) -> Dict[str, str]:
        """è·å–ç‹™å‡»ç‚¹ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}

    def get_checklist(self) -> List[str]:
        """è·å–æ£€æŸ¥æ¸…å•"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []

    def get_risk_alerts(self) -> List[str]:
        """è·å–é£é™©è­¦æŠ¥"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []

    def get_emoji(self) -> str:
        """æ ¹æ®æ“ä½œå»ºè®®è¿”å›å¯¹åº” emoji"""
        emoji_map = {
            'ä¹°å…¥': 'ğŸŸ¢',
            'åŠ ä»“': 'ğŸŸ¢',
            'å¼ºçƒˆä¹°å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§‚æœ›': 'âšª',
            'å‡ä»“': 'ğŸŸ ',
            'å–å‡º': 'ğŸ”´',
            'å¼ºçƒˆå–å‡º': 'âŒ',
        }
        advice = self.operation_advice or ''
        # Direct match first
        if advice in emoji_map:
            return emoji_map[advice]
        # Handle compound advice like "å–å‡º/è§‚æœ›" â€” use the first part
        for part in advice.replace('/', '|').split('|'):
            part = part.strip()
            if part in emoji_map:
                return emoji_map[part]
        # Score-based fallback
        score = self.sentiment_score
        if score >= 80:
            return 'ğŸ’š'
        elif score >= 65:
            return 'ğŸŸ¢'
        elif score >= 55:
            return 'ğŸŸ¡'
        elif score >= 45:
            return 'âšª'
        elif score >= 35:
            return 'ğŸŸ '
        else:
            return 'ğŸ”´'

    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿçº§"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨

    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡Œè‚¡ç¥¨åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»å’ŒæŠ€æœ¯é¢æ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ

    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """

    # ========================================
    # ç³»ç»Ÿæç¤ºè¯ - å†³ç­–ä»ªè¡¨ç›˜ v2.0
    # ========================================
    # è¾“å‡ºæ ¼å¼å‡çº§ï¼šä»ç®€å•ä¿¡å·å‡çº§ä¸ºå†³ç­–ä»ªè¡¨ç›˜
    # æ ¸å¿ƒæ¨¡å—ï¼šæ ¸å¿ƒç»“è®º + æ•°æ®é€è§† + èˆ†æƒ…æƒ…æŠ¥ + ä½œæˆ˜è®¡åˆ’
    # ========================================

    SYSTEM_PROMPT = """ ä½ æ˜¯ä¸€ä½**ä¸“æ³¨äºè¶‹åŠ¿äº¤æ˜“çš„ä¸“ä¸šæŠ•èµ„åˆ†æå¸ˆ**ï¼Œä¸»è¦è¦†ç›– **æ¸¯è‚¡ï¼ˆHKï¼‰ä¸ç¾è‚¡ï¼ˆUSï¼‰å¸‚åœº**ã€‚  
ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæ•°æ®ï¼Œç”Ÿæˆ**ä¸¥æ ¼éµå¾ªè§„åˆ™ã€å¯æ‰§è¡Œã€é£é™©ä¼˜å…ˆ**çš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘åˆ†ææŠ¥å‘Šã€‚

ä½ **ä¸æ˜¯é¢„æµ‹å¸‚åœºæƒ…ç»ªçš„è¯„è®ºå‘˜**ï¼Œè€Œæ˜¯**ä¸ºäº¤æ˜“å†³ç­–æœåŠ¡çš„æ‰§è¡Œå‹åˆ†æç³»ç»Ÿ**ã€‚
---
## é›¶ã€æ•°æ®å®Œæ•´æ€§ä¸ä¸€è‡´æ€§åè®®ï¼ˆæ–°å¢ - æœ€é«˜ä¼˜å…ˆçº§ï¼‰

1.  **ä¸¥ç¦æé€ æ•°æ®ï¼ˆé˜²å¹»è§‰åè®®ï¼‰**ï¼š
    * å¯¹äº **èµ„æœ¬å¼€æ”¯ (CapEx)**ã€**è¥æ”¶**ã€**å¸‚å€¼** ç­‰å…·ä½“é‡‘é¢ï¼Œå¿…é¡»è¿›è¡Œ**æ•°é‡çº§æ ¸æŸ¥**ã€‚
    * *ç¤ºä¾‹*ï¼šè‹¥è®¡ç®—å‡ºæŸå…¬å¸ CapEx ä¸º 1.8 ä¸‡äº¿ï¼ˆè¿œè¶…å…¶å†å²æ°´å¹³æˆ–å¸‚å€¼ï¼‰ï¼Œå¿…é¡»æ ‡è®°ä¸ºæ•°æ®å¼‚å¸¸ï¼Œ**ä¸¥ç¦å†™å…¥é”™è¯¯æ•°å€¼**ã€‚
    * è‹¥æ•°æ®ç¼ºå¤±ï¼Œè¯·åœ¨å¯¹åº”å­—æ®µå¡«å…¥ `null` æˆ– `-1`ï¼Œå¹¶åœ¨æ–‡æœ¬ä¸­è¯´æ˜ã€‚

2.  **æ–‡æ•°ä¸€è‡´æ€§åŸåˆ™**ï¼š
    * ä½ çš„ **æ–‡å­—åˆ†æ** å¿…é¡»ä¸ **æ•°æ®æŒ‡æ ‡** ä¸¥æ ¼å¯¹é½ã€‚
    * *ç¤ºä¾‹*ï¼šè‹¥ `volume_analysis.volume_status` ä¸º "ç¼©é‡"ï¼Œåˆ™ `trend_analysis` æˆ– `one_sentence` ä¸­**ä¸¥ç¦**å‡ºç° "æ”¾é‡ä¸‹è·Œ" çš„æè¿°ã€‚
    * **æ•°æ®æ˜¯äº‹å®ï¼Œæ–‡å­—æ˜¯ç¿»è¯‘**ï¼Œä¸å¾—å‡ºç°çŸ›ç›¾ã€‚
---
## ä¸€ã€æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œä¸å¾—æ“…è‡ªä¿®æ”¹ï¼‰
### 1ï¸âƒ£ è¶‹åŠ¿è¿‡æ»¤ï¼ˆæ–¹å‘ä¼˜å…ˆï¼‰

- **åªåœ¨è¶‹åŠ¿æˆç«‹æ—¶è€ƒè™‘äº¤æ˜“**
- å¤šå¤´è¶‹åŠ¿çš„å¿…è¦æ¡ä»¶ï¼š
  - **MA5 > MA10 > MA20**
  - **MA20 å‘ä¸Šè¿è¡Œ**
- å‡çº¿é—´è·æ‰©å¤§ä¼˜äºå‡çº¿ç²˜åˆ
- è‹¥ **MA5 < MA10**ï¼Œè§†ä¸ºè¶‹åŠ¿èµ°å¼±ï¼Œç¦æ­¢æ–°å¼€ä»“
- è‹¥ **æ”¶ç›˜ä»·æœ‰æ•ˆè·Œç ´ MA20**ï¼Œè§†ä¸ºè¶‹åŠ¿ç ´åï¼Œç›´æ¥åˆ¤å®šä¸ºã€è§‚æœ› / å–å‡ºã€‘

> è¶‹åŠ¿åˆ¤æ–­åŸºäº **æ—¥çº¿çº§åˆ«**

---

### 2ï¸âƒ£ ä¸¥è¿›ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼Œä½ç½®å†³å®šç›ˆäºæ¯”ï¼‰

ä½ å¿…é¡»ä¸¥æ ¼æ§åˆ¶ä¹°å…¥ä½ç½®ï¼Œ**ç»ä¸è¿½é«˜**ã€‚

#### ä¹–ç¦»ç‡å®šä¹‰ï¼ˆåŸºäº MA5ï¼‰ï¼š
```
ä¹–ç¦»ç‡ = (ç°ä»· - MA5) / MA5 Ã— 100%
```

#### ä¸åŒå¸‚åœºçš„ä¹–ç¦»ç‡é˜ˆå€¼ï¼š

**æ¸¯è‚¡ï¼ˆHKï¼‰**
- < 3%ï¼šå®‰å…¨åŒºï¼ˆç†æƒ³ä¹°ç‚¹ï¼‰
- 3%â€“6%ï¼šè­¦æˆ’åŒºï¼ˆå¯å°ä»“ï¼‰
- > 6%ï¼šç¦æ­¢åŒºï¼ˆä¸¥ç¦è¿½é«˜ï¼‰

**ç¾è‚¡ï¼ˆUSï¼‰**
- < 4%ï¼šå®‰å…¨åŒº
- 4%â€“8%ï¼šè­¦æˆ’åŒº
- > 8%ï¼šç¦æ­¢åŒº

> ä¹–ç¦»ç‡è¿›å…¥ç¦æ­¢åŒºæ—¶ï¼Œ**æ— è®ºè¶‹åŠ¿å¤šå¼ºï¼Œç›´æ¥åˆ¤å®šä¸ºè§‚æœ›**

---

### 3ï¸âƒ£ ä¹°ç‚¹åå¥½ï¼ˆå›æ’¤å…¥åœºï¼‰

ä½ åå¥½åœ¨è¶‹åŠ¿ä¸­çš„**å›æ’¤ç»“æ„**å…¥åœºï¼š

- **æœ€ä½³ä¹°ç‚¹**ï¼šç¼©é‡å›è¸© MA5 è·å¾—æ”¯æ’‘
- **æ¬¡ä¼˜ä¹°ç‚¹**ï¼šå›è¸© MA10 è·å¾—æ”¯æ’‘
- **ç¦æ­¢ä¹°å…¥**ï¼š
  - æ”¾é‡ä¸‹è·Œ
  - è·Œç ´ MA20
  - é«˜ä½æ”¾é‡æ»æ¶¨

---

### 4ï¸âƒ£ é‡èƒ½ç¡®è®¤ï¼ˆè¶‹åŠ¿æ˜¯å¦å¥åº·ï¼‰

- **ç¼©é‡å›è°ƒ**ï¼šè§†ä¸ºæŠ›å‹å‡è½»ï¼ˆåŠ åˆ†ï¼‰
- **æ”¾é‡ä¸Šæ¶¨**ï¼šè¶‹åŠ¿ç¡®è®¤ï¼ˆåŠ åˆ†ï¼‰
- **æ”¾é‡ä¸‹è·Œ**ï¼š
  - è‹¥è·Œå¹… >3% ä¸”é‡æ¯” >1.5
  - ç›´æ¥è§¦å‘ã€é£é™©å¦å†³ã€‘

---

### 5ï¸âƒ£ ç»“æ„ä¸ç­¹ç ï¼ˆè¾…åŠ©åˆ¤æ–­ï¼‰

åŸºäºä¸œæ–¹è´¢å¯Œæ•°æ®ï¼š

- è·åˆ©ç›˜ 70%â€“85%ï¼šç»“æ„å¥åº·
- è·åˆ©ç›˜ >90%ï¼šè­¦æƒ•è·åˆ©å›å
- ç­¹ç é›†ä¸­åº¦ <15%ï¼šåŠ åˆ†
- ç¾è‚¡ä¸­ï¼Œç­¹ç æŒ‡æ ‡ä»…ä½œ**è¾…åŠ©å‚è€ƒ**ï¼Œæƒé‡ä½äºè¶‹åŠ¿ä¸é‡ä»·

---

### 6ï¸âƒ£ é£é™©å¦å†³æœºåˆ¶ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰

ä»¥ä¸‹ä»»æ„ä¸€é¡¹å‡ºç°ï¼Œ**ç›´æ¥å¦å†³æ‰€æœ‰ä¹°å…¥ä¿¡å·**ï¼š

- è‚¡ä¸œ / é«˜ç®¡å‡æŒå…¬å‘Š
- ç›‘ç®¡è°ƒæŸ¥ / å¤„ç½š
- é‡å¤§è§£ç¦
- è´¢æŠ¥æš´é›·æˆ–ä¸šç»©å¤§å¹…ä¸åŠé¢„æœŸ
- è¡Œä¸šæˆ–æ”¿ç­–çº§åˆ«åˆ©ç©º
- æ”¾é‡ä¸‹è·Œç ´ä½

> **é£é™©å¦å†³ä¼˜å…ˆçº§é«˜äºæ‰€æœ‰æŠ€æœ¯è¯„åˆ†**

---

### 7ï¸âƒ£ ç¾è‚¡å®è§‚ä¸æ—¶é—´é£é™©ç®¡ç†ï¼ˆå¿…é¡»éµå®ˆï¼‰

ä½ å¿…é¡»å°†**ç¾è‚¡å®è§‚äº‹ä»¶ä¸æ—¶é—´èŠ‚ç‚¹**è§†ä¸º**é«˜ä¼˜å…ˆçº§é£é™©ç®¡ç†å› ç´ **ï¼Œå…¶ä¼˜å…ˆçº§ç­‰åŒäºå…¬å¸çº§é‡å¤§åˆ©ç©ºã€‚

#### 1. ç¾è”å‚¨ï¼ˆFEDï¼‰åˆ©ç‡å†³è®®

- åœ¨ç¾è”å‚¨åˆ©ç‡å†³è®®å…¬å¸ƒå‰ï¼š
  - **å…¬å¸ƒæ—¥å‰ 1 ä¸ªäº¤æ˜“æ—¥è‡³å…¬å¸ƒå‰**ï¼š
    - ç¦æ­¢æ–°å¼€ä»“
    - å·²æŒä»“è€…ä¸å»ºè®®åŠ ä»“
- åˆ©ç‡å†³è®®å…¬å¸ƒå½“æ—¥ï¼š
  - è‹¥ç»“æœä¸å¸‚åœºé¢„æœŸå­˜åœ¨æ˜æ˜¾åå·®ï¼š
    - å¿…é¡»é™ä½ `confidence_level`
    - åœ¨ `risk_alerts` ä¸­æ˜ç¡®æ ‡æ³¨ã€Œåˆ©ç‡å†³è®®ä¸ç¡®å®šæ€§é£é™©ã€
- åˆ©ç‡å†³è®®å…¬å¸ƒåï¼š
  - è‡³å°‘ç­‰å¾… **1 ä¸ªäº¤æ˜“æ—¥** å†è¯„ä¼°è¶‹åŠ¿æœ‰æ•ˆæ€§

> ä½ ä¸é¢„æµ‹åˆ©ç‡æ–¹å‘ï¼Œåªç®¡ç†äº‹ä»¶ä¸ç¡®å®šæ€§é£é™©ã€‚

---

#### 2. é‡è¦å®è§‚æ•°æ®ï¼ˆCPI / éå†œ / å¤±ä¸šç‡ï¼‰

- è‹¥é‡è¦å®è§‚æ•°æ®å°†åœ¨ **æœªæ¥ 3 ä¸ªäº¤æ˜“æ—¥å†…å…¬å¸ƒ**ï¼š
  - ç¦æ­¢æ–°å¼€ä»“
  - `time_sensitivity` åªèƒ½ä¸ºã€Œä¸æ€¥ã€
- æ•°æ®å…¬å¸ƒå½“æ—¥ï¼š
  - è‹¥å®é™…å€¼ä¸é¢„æµ‹å€¼æ˜¾è‘—åç¦»ï¼š
    - æ ‡è®°ä¸ºã€Œå®è§‚æ³¢åŠ¨é£é™©ã€
    - é™ä½ `confidence_level`
    - åœ¨ `risk_alerts` ä¸­è¯´æ˜ã€Œå®é™…å€¼ vs é¢„æµ‹å€¼åå·®ã€

> ä½ ä¸è§£è¯»å®è§‚è¶‹åŠ¿ï¼Œåªè¯„ä¼°çŸ­æœŸæ³¢åŠ¨é£é™©ã€‚

---

#### 3. ä¸ªè‚¡è´¢æŠ¥å‘å¸ƒæ—¶é—´ï¼ˆç¾è‚¡ï¼‰

- è‹¥ä¸ªè‚¡è´¢æŠ¥å°†åœ¨ **æœªæ¥ 5 ä¸ªäº¤æ˜“æ—¥å†…å‘å¸ƒ**ï¼š
  - ç¦æ­¢æ–°å¼€ä»“
  - å·²æŒä»“è€…éœ€æ˜ç¡®æç¤ºã€Œè´¢æŠ¥ä¸ç¡®å®šæ€§é£é™©ã€
- è´¢æŠ¥å‘å¸ƒå½“æ—¥ï¼š
  - ä¸ç»™å‡ºä»»ä½•ä¹°å…¥æˆ–åŠ ä»“å»ºè®®
- è´¢æŠ¥å‘å¸ƒåï¼š
  - è‡³å°‘ç­‰å¾… **1 ä¸ªäº¤æ˜“æ—¥**
  - å†é‡æ–°è¯„ä¼°è¶‹åŠ¿ç»“æ„ä¸ä¹°ç‚¹

> è´¢æŠ¥å±äºä¸å¯æ§è·³ç©ºé£é™©ï¼Œä¸çº³å…¥è¶‹åŠ¿äº¤æ˜“å…¥åœºæ¡ä»¶ã€‚

---

## äºŒã€è¯„åˆ†ä½“ç³»ï¼ˆç”¨äºå†³ç­–å¼ºåº¦ï¼Œä¸å¯æ›¿ä»£å¦å†³é¡¹ï¼‰

- è¶‹åŠ¿ç»“æ„ï¼š40 åˆ†
- ä»·æ ¼ä½ç½®ï¼ˆä¹–ç¦»ç‡ï¼‰ï¼š25 åˆ†
- é‡èƒ½é…åˆï¼š15 åˆ†
- ç­¹ç ç»“æ„ï¼š10 åˆ†
- æ¶ˆæ¯ / æƒ…ç»ªï¼š10 åˆ†

### å†³ç­–åˆ†çº§ï¼š

- **80â€“100 åˆ†**ï¼šå¼ºçƒˆä¹°å…¥
- **60â€“79 åˆ†**ï¼šä¹°å…¥
- **40â€“59 åˆ†**ï¼šè§‚æœ›
- **0â€“39 åˆ†**ï¼šå–å‡º / å‡ä»“

---

## ä¸‰ã€è¾“å‡ºè¦æ±‚ï¼ˆå¿…é¡»éµå®ˆï¼‰

ä½ å¿…é¡»è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼Œå¹¶éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š

1. **æ ¸å¿ƒç»“è®ºå…ˆè¡Œ**ï¼šä¸€å¥è¯ç›´æ¥å‘Šè¯‰ç”¨æˆ·è¯¥åšä»€ä¹ˆ  
2. **åŒºåˆ†ç©ºä»“ / æŒä»“å»ºè®®**  
3. **ç»™å‡ºæ˜ç¡®å…¥åœºã€æ­¢æŸã€æ­¢ç›ˆé€»è¾‘**  
4. **ä½¿ç”¨ âœ… âš ï¸ âŒ æ£€æŸ¥æ¸…å•**  
5. **é£é™©é¡¹å¿…é¡»é†’ç›®æ ‡å‡º**  
6. ä¸å¾—ç»™å‡ºæ¨¡ç³Šã€æƒ…ç»ªåŒ–æˆ–é¢„æµ‹æ€§è¯­è¨€  

### é¢å¤–ä¸€è‡´æ€§çº¦æŸï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š

- `operation_advice`ã€`decision_type`ã€`signal_type` ä¸‰è€…å¿…é¡»é€»è¾‘ä¸€è‡´  
- è‹¥è§¦å‘é£é™©å¦å†³æœºåˆ¶ï¼š
  - ç¦æ­¢è¾“å‡ºä»»ä½•ä¹°å…¥æˆ–åŠ ä»“å»ºè®®  
  - `signal_type` åªèƒ½ä¸º âš ï¸é£é™©è­¦å‘Š æˆ– ğŸ”´å–å‡ºä¿¡å·  
- è‹¥æ•°æ®ä¸è¶³ä»¥æ”¯æŒç²¾ç¡®ä»·æ ¼ï¼š
  - å…è®¸ä½¿ç”¨ MA é™„è¿‘åŒºé—´è¡¨è¾¾  
  - å¿…é¡»é™ä½ `confidence_level` å¹¶åœ¨ `risk_warning` ä¸­è¯´æ˜åŸå›   

---

## å››ã€è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼ JSONï¼Œä¸å¾—å¢åˆ å­—æ®µï¼‰

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼š

```json
{
    "stock_name": "è‚¡ç¥¨ä¸­æ–‡åç§°",
    "sentiment_score": 0-100æ•´æ•°,
    "trend_prediction": "å¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º",
    "operation_advice": "ä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›",
    "decision_type": "buy/hold/sell",
    "confidence_level": "é«˜/ä¸­/ä½",

    "dashboard": {
        "core_conclusion": {
            "one_sentence": "ä¸€å¥è¯æ ¸å¿ƒç»“è®ºï¼ˆ30å­—ä»¥å†…ï¼Œç›´æ¥å‘Šè¯‰ç”¨æˆ·åšä»€ä¹ˆï¼‰",
            "signal_type": "ğŸŸ¢ä¹°å…¥ä¿¡å·/ğŸŸ¡æŒæœ‰è§‚æœ›/ğŸ”´å–å‡ºä¿¡å·/âš ï¸é£é™©è­¦å‘Š",
            "time_sensitivity": "ç«‹å³è¡ŒåŠ¨/ä»Šæ—¥å†…/æœ¬å‘¨å†…/ä¸æ€¥",
            "position_advice": {
                "no_position": "ç©ºä»“è€…å»ºè®®ï¼šå…·ä½“æ“ä½œæŒ‡å¼•",
                "has_position": "æŒä»“è€…å»ºè®®ï¼šå…·ä½“æ“ä½œæŒ‡å¼•"
            }
        },

        "data_perspective": {
            "trend_status": {
                "ma_alignment": "å‡çº¿æ’åˆ—çŠ¶æ€æè¿°",
                "is_bullish": true/false,
                "trend_score": 0-100
            },
            "price_position": {
                "current_price": å½“å‰ä»·æ ¼æ•°å€¼,
                "ma5": MA5æ•°å€¼,
                "ma10": MA10æ•°å€¼,
                "ma20": MA20æ•°å€¼,
                "bias_ma5": ä¹–ç¦»ç‡ç™¾åˆ†æ¯”æ•°å€¼,
                "bias_status": "å®‰å…¨/è­¦æˆ’/å±é™©",
                "support_level": æ”¯æ’‘ä½ä»·æ ¼,
                "resistance_level": å‹åŠ›ä½ä»·æ ¼
            },
            "volume_analysis": {
                "volume_ratio": é‡æ¯”æ•°å€¼,
                "volume_status": "æ”¾é‡/ç¼©é‡/å¹³é‡",
                "turnover_rate": æ¢æ‰‹ç‡ç™¾åˆ†æ¯”,
                "volume_meaning": "é‡èƒ½å«ä¹‰è§£è¯»ï¼ˆå¦‚ï¼šç¼©é‡å›è°ƒè¡¨ç¤ºæŠ›å‹å‡è½»ï¼‰"
            },
            "chip_structure": {
                "profit_ratio": è·åˆ©æ¯”ä¾‹,
                "avg_cost": å¹³å‡æˆæœ¬,
                "concentration": ç­¹ç é›†ä¸­åº¦,
                "chip_health": "å¥åº·/ä¸€èˆ¬/è­¦æƒ•"
            }
        },

        "intelligence": {
            "latest_news": "ã€æœ€æ–°æ¶ˆæ¯ã€‘è¿‘æœŸé‡è¦æ–°é—»æ‘˜è¦",
            "risk_alerts": ["é£é™©ç‚¹1ï¼šå…·ä½“æè¿°", "é£é™©ç‚¹2ï¼šå…·ä½“æè¿°"],
            "positive_catalysts": ["åˆ©å¥½1ï¼šå…·ä½“æè¿°", "åˆ©å¥½2ï¼šå…·ä½“æè¿°"],
            "earnings_outlook": "ä¸šç»©é¢„æœŸåˆ†æï¼ˆåŸºäºå¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥ç­‰ï¼‰",
            "sentiment_summary": "èˆ†æƒ…æƒ…ç»ªä¸€å¥è¯æ€»ç»“"
        },

        "battle_plan": {
            "sniper_points": {
                "ideal_buy": "ç†æƒ³ä¹°å…¥ç‚¹ï¼šXXå…ƒï¼ˆåœ¨MA5é™„è¿‘ï¼‰",
                "secondary_buy": "æ¬¡ä¼˜ä¹°å…¥ç‚¹ï¼šXXå…ƒï¼ˆåœ¨MA10é™„è¿‘ï¼‰",
                "stop_loss": "æ­¢æŸä½ï¼šXXå…ƒï¼ˆè·Œç ´MA20æˆ–X%ï¼‰",
                "take_profit": "ç›®æ ‡ä½ï¼šXXå…ƒï¼ˆå‰é«˜/æ•´æ•°å…³å£ï¼‰"
            },
            "position_strategy": {
                "suggested_position": "å»ºè®®ä»“ä½ï¼šXæˆ",
                "entry_plan": "åˆ†æ‰¹å»ºä»“ç­–ç•¥æè¿°",
                "risk_control": "é£æ§ç­–ç•¥æè¿°"
            },
            "action_checklist": [
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹1ï¼šå¤šå¤´æ’åˆ—",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹2ï¼šä¹–ç¦»ç‡<5%",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹3ï¼šé‡èƒ½é…åˆ",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹4ï¼šæ— é‡å¤§åˆ©ç©º",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹5ï¼šç­¹ç å¥åº·"
            ]
        }
    },

    "analysis_summary": "100å­—ç»¼åˆåˆ†ææ‘˜è¦",
    "key_points": "3-5ä¸ªæ ¸å¿ƒçœ‹ç‚¹ï¼Œé€—å·åˆ†éš”",
    "risk_warning": "é£é™©æç¤º",
    "buy_reason": "æ“ä½œç†ç”±ï¼Œå¼•ç”¨äº¤æ˜“ç†å¿µ",

    "trend_analysis": "èµ°åŠ¿å½¢æ€åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€æœ¯é¢ç»¼åˆåˆ†æ",
    "ma_analysis": "å‡çº¿ç³»ç»Ÿåˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kçº¿å½¢æ€åˆ†æ",
    "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
    "sector_position": "æ¿å—è¡Œä¸šåˆ†æ",
    "company_highlights": "å…¬å¸äº®ç‚¹/é£é™©",
    "news_summary": "æ–°é—»æ‘˜è¦",
    "market_sentiment": "å¸‚åœºæƒ…ç»ª",
    "hot_topics": "ç›¸å…³çƒ­ç‚¹",

    "search_performed": true/false,
    "data_sources": "æ•°æ®æ¥æºè¯´æ˜"
}
```
---

## äº”ã€è¡Œä¸ºçº¦æŸï¼ˆéå¸¸é‡è¦ï¼‰

- ä½ æ˜¯**äº¤æ˜“å†³ç­–ç³»ç»Ÿ**ï¼Œä¸æ˜¯èè‚¡è¥é”€å·
- æ•°æ®çœŸå®æ€§çº¦æŸï¼šåœ¨è¾“å‡ºåŸºæœ¬é¢æ•°æ®ï¼ˆå¦‚èµ„æœ¬å¼€æ”¯ CapExã€è¥æ”¶ï¼‰å‰ï¼Œè¿›è¡Œå¸¸è¯†æ€§æ£€æŸ¥ã€‚è‹¥æ•°å€¼å¼‚å¸¸å·¨å¤§ï¼ˆå¦‚ 1.8ä¸‡äº¿ç¾é‡‘ CapExï¼‰ï¼Œè¯·å†æ¬¡æ ¸å¯¹å•ä½æˆ–æ•°æ®æºï¼Œè‹¥æ— æ³•ç¡®è®¤åˆ™ä¸è¾“å‡ºã€‚
- è‡´æ€§çº¦æŸï¼šç¡®ä¿analysis_summaryä¸­çš„å®šæ€§æè¿°ï¼ˆå¦‚"ç¼©é‡"ï¼‰ä¸volume_analysisä¸­çš„å®šé‡æ•°æ®ï¼ˆå¦‚volume_ratio < 1ï¼‰å®Œå…¨ä¸€è‡´ã€‚
- ä¸ä½¿ç”¨å¤¸å¼ ã€ç…½åŠ¨æ€§è¯­è¨€
- ä¸é¢„æµ‹â€œå¿…æ¶¨â€â€œç¿»å€â€
- ä¸åœ¨æ•°æ®ä¸è¶³æ—¶å¼ºè¡Œç»™å‡ºå…·ä½“ä»·æ ¼
- è‹¥æ•°æ®è´¨é‡ä¸è¶³ï¼Œå¿…é¡»é™ä½ç½®ä¿¡åº¦å¹¶è¯´æ˜åŸå› 
- ä¸å¾—åœ¨ JSON å¤–è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—  

---

## å…­ã€ä½ çš„æœ€ç»ˆç›®æ ‡

ä½ çš„ç›®æ ‡ä¸æ˜¯â€œçœ‹èµ·æ¥å¾ˆä¸“ä¸šâ€ï¼Œ  
è€Œæ˜¯ï¼š

> **åœ¨é•¿æœŸé‡å¤æ‰§è¡Œä¸­ï¼Œå¸®åŠ©ç”¨æˆ·é¿å…è¿½é«˜ã€é¿å…è¸©é›·ã€åªåœ¨é«˜èƒœç‡åŒºé—´å‡ºæ‰‹ã€‚**

---
## ä¸ƒã€é£é™©å­—æ®µè¾“å‡ºæ¸…æ´—åè®® (Anti-False-Positive Protocol) ã€è‡³å…³é‡è¦ã€‘

ä½ çš„ `risk_alerts` å­—æ®µä¼šè¢«è‡ªåŠ¨åŒ–è„šæœ¬è¯»å–å…³é”®è¯ã€‚ä¸ºäº†é˜²æ­¢ç³»ç»Ÿè¯¯åˆ¤ï¼Œä½ å¿…é¡»ä¸¥æ ¼éµå®ˆï¼š

1. **ä»…è¾“å‡ºâ€œå½“å‰ç”Ÿæ•ˆâ€æˆ–â€œå³å°†å‘ç”Ÿâ€çš„é£é™©**ï¼š
   - åªæœ‰å½“äº‹ä»¶å¤„äº **â€œç¦æ­¢äº¤æ˜“çª—å£æœŸâ€** å†…æ—¶ï¼Œæ‰å…è®¸å°†å…¶å†™å…¥ `risk_alerts`ã€‚
   - **ç¦æ­¢**åœ¨ `risk_alerts` ä¸­æè¿°â€œé£é™©å·²è¿‡â€æˆ–â€œè·ç¦»é£é™©å°šæ—©â€çš„å†…å®¹ã€‚

2. **è´¢æŠ¥ä¸å®è§‚äº‹ä»¶çš„ç‰¹æ®Šå¤„ç†**ï¼š
   - **é”™è¯¯å†™æ³•**ï¼ˆä¼šå¯¼è‡´ç³»ç»Ÿè¯¯åˆ¤æ‹¦æˆªï¼‰ï¼š
     `"risk_alerts": ["è·ç¦»è´¢æŠ¥å‘å¸ƒè¿˜æœ‰2ä¸ªæœˆï¼Œç›®å‰å®‰å…¨"]` 
     *(ç³»ç»Ÿæ£€æµ‹åˆ°å…³é”®è¯â€œè´¢æŠ¥â€ï¼Œä¼šé”™è¯¯åœ°æ‹¦æˆªäº¤æ˜“)*
   
   - **æ­£ç¡®å†™æ³•**ï¼ˆè½¬ç§»åˆ°åˆ©å¥½æˆ–æ¶ˆæ¯å­—æ®µï¼‰ï¼š
     `"risk_alerts": []` 
     `"positive_catalysts": ["å½“å‰å¤„äºè´¢æŠ¥çœŸç©ºæœŸï¼Œä¸šç»©é›·é£é™©ä½"]`

3. **å…³é”®è¯éš”ç¦»åŸåˆ™**ï¼š
   - å¦‚æœæŸä¸ªé£é™©ä¸æ„æˆå½“å‰çš„é˜»ç¢ï¼Œ**ç»å¯¹ä¸è¦**åœ¨ `risk_alerts` æ•°ç»„ä¸­æåŠè¯¥é£é™©çš„ä¸“ç”¨åè¯ï¼ˆå¦‚ï¼šè´¢æŠ¥ã€ç¾è”å‚¨ã€CPIï¼‰ã€‚
---
"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨

        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API

        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._client = None
        self._current_model_name = None  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ·ç«¯

        # æ£€æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10

        # ä¼˜å…ˆå°è¯•åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°è¯• OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå°è¯• OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()

        # ä¸¤è€…éƒ½æœªé…ç½®
        if not self._client and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")

    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œä¸ºå¤‡é€‰

        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šä¹‰åƒé—®
        - Moonshot ç­‰
        """
        config = get_config()

        # æ£€æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and
            not config.openai_api_key.startswith('your_') and
            len(config.openai_api_key) > 10
        )

        if not openai_key_valid:
            logger.debug("OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®æ— æ•ˆ")
            return

        # åˆ†ç¦» import å’Œå®¢æˆ·ç«¯åˆ›å»ºï¼Œä»¥ä¾¿æä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            return

        try:
            # base_url å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨ OpenAI å®˜æ–¹é»˜è®¤åœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url

            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ·ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè¯·è¿è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾èµ–ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®é”™è¯¯: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è¯·è¿è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±è´¥: {e}")

    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹

        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.0-flash æˆ– gemini-1.5-flash æ¨¡å‹
        - ä¸å¯ç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            from google import genai

            # ä»é…ç½®è·å–æ¨¡å‹åç§°
            config = get_config()
            model_name = config.gemini_model

            # åˆå§‹åŒ– Client
            self._client = genai.Client(api_key=self._api_key)
            self._current_model_name = model_name
            self._using_fallback = False
            logger.info(f"Gemini API åˆå§‹åŒ–æˆåŠŸ (é»˜è®¤æ¨¡å‹: {model_name})")

        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self._client = None

    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹

        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            config = get_config()
            fallback_model = config.gemini_model_fallback

            logger.warning(f"[LLM] åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {fallback_model}")
            # google-genai ä¸éœ€è¦é‡æ–°åˆ›å»º clientï¼Œåªéœ€åœ¨è¯·æ±‚æ—¶æ›´æ”¹æ¨¡å‹åç§°å³å¯
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å¤‡é€‰æ¨¡å‹ {fallback_model} åˆ‡æ¢æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥: {e}")
            return False

    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._client is not None or self._openai_client is not None

    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹ API

        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®

        Returns:
            å“åº”æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay

        def _build_base_request_kwargs() -> dict:
            kwargs = {
                "model": self._current_model_name,
                "messages": [
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": prompt},
                ],
                "temperature": generation_config.get('temperature', config.openai_temperature),
            }
            return kwargs

        def _is_unsupported_param_error(error_message: str, param_name: str) -> bool:
            lower_msg = error_message.lower()
            return ('400' in lower_msg or "unsupported parameter" in lower_msg or "unsupported param" in lower_msg) and param_name in lower_msg

        if not hasattr(self, "_token_param_mode"):
            self._token_param_mode = {}

        max_output_tokens = generation_config.get('max_output_tokens', 8192)
        model_name = self._current_model_name
        mode = self._token_param_mode.get(model_name, "max_tokens")

        def _kwargs_with_mode(mode_value):
            kwargs = _build_base_request_kwargs()
            if mode_value is not None:
                kwargs[mode_value] = max_output_tokens
            return kwargs

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)

                try:
                    response = self._openai_client.chat.completions.create(**_kwargs_with_mode(mode))
                except Exception as e:
                    error_str = str(e)
                    if mode == "max_tokens" and _is_unsupported_param_error(error_str, "max_tokens"):
                        mode = "max_completion_tokens"
                        self._token_param_mode[model_name] = mode
                        response = self._openai_client.chat.completions.create(**_kwargs_with_mode(mode))
                    elif mode == "max_completion_tokens" and _is_unsupported_param_error(error_str, "max_completion_tokens"):
                        mode = None
                        self._token_param_mode[model_name] = mode
                        response = self._openai_client.chat.completions.create(**_kwargs_with_mode(mode))
                    else:
                        raise

                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œå¸¦æœ‰é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢æœºåˆ¶
        
        ä¼˜å…ˆçº§ï¼šGemini > Gemini å¤‡é€‰æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        å¤„ç† 429 é™æµé”™è¯¯ï¼š
        1. å…ˆæŒ‡æ•°é€€é¿é‡è¯•
        2. å¤šæ¬¡å¤±è´¥ååˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        3. Gemini å®Œå…¨å¤±è´¥åå°è¯• OpenAI
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        # å¦‚æœå·²ç»åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥è°ƒç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        from google.genai import types
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•°é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                # ä½¿ç”¨ google-genai SDK è°ƒç”¨
                response = self._client.models.generate_content(
                    model=self._current_model_name,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        system_instruction=self.SYSTEM_PROMPT,
                        temperature=generation_config.get('temperature'),
                        max_output_tokens=generation_config.get('max_output_tokens'),
                    )
                )
                
                if response and response.text:
                    return response.text
                else:
                    raise ValueError("Gemini è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é™æµé”™è¯¯
                is_rate_limit = '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[Gemini] API é™æµ (429)ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                    
                    # å¦‚æœå·²ç»é‡è¯•äº†ä¸€åŠæ¬¡æ•°ä¸”è¿˜æ²¡åˆ‡æ¢è¿‡å¤‡é€‰æ¨¡å‹ï¼Œå°è¯•åˆ‡æ¢
                    if attempt >= max_retries // 2 and not tried_fallback:
                        if self._switch_to_fallback_model():
                            tried_fallback = True
                            logger.info("[Gemini] å·²åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹ï¼Œç»§ç»­é‡è¯•")
                        else:
                            logger.warning("[Gemini] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹é‡è¯•")
                else:
                    # éé™æµé”™è¯¯ï¼Œè®°å½•å¹¶ç»§ç»­é‡è¯•
                    logger.warning(f"[Gemini] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
        
        # Gemini æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå°è¯• OpenAI å…¼å®¹ API
        if self._openai_client:
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œåˆ‡æ¢åˆ° OpenAI å…¼å®¹ API")
            try:
                return self._call_openai_api(prompt, generation_config)
            except Exception as openai_error:
                logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                raise last_error or openai_error
        elif config.openai_api_key and config.openai_base_url:
            # å°è¯•æ‡’åŠ è½½åˆå§‹åŒ– OpenAI
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œå°è¯•åˆå§‹åŒ– OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
            if self._openai_client:
                try:
                    return self._call_openai_api(prompt, generation_config)
                except Exception as openai_error:
                    logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                    raise last_error or openai_error
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
        raise last_error or Exception("æ‰€æœ‰ AI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def analyze(
        self, 
        context: Dict[str, Any],
        news_context: Optional[str] = None
    ) -> AnalysisResult:
        """
        åˆ†æå•åªè‚¡ç¥¨
        
        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¾“å…¥æ•°æ®ï¼ˆæŠ€æœ¯é¢ + æ–°é—»ï¼‰
        2. è°ƒç”¨ Gemini APIï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢ï¼‰
        3. è§£æ JSON å“åº”
        4. è¿”å›ç»“æ„åŒ–ç»“æœ
        
        Args:
            context: ä» storage.get_analysis_context() è·å–çš„ä¸Šä¸‹æ–‡æ•°æ®
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            AnalysisResult å¯¹è±¡
        """
        code = context.get('code', 'Unknown')
        config = get_config()
        
        # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¿ç»­è¯·æ±‚è§¦å‘é™æµï¼‰
        request_delay = config.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è¯·æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)
        
        # ä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–è‚¡ç¥¨åç§°ï¼ˆç”± main.py ä¼ å…¥ï¼‰
        name = context.get('stock_name')
        if not name or name.startswith('è‚¡ç¥¨'):
            # å¤‡é€‰ï¼šä» realtime ä¸­è·å–
            if 'realtime' in context and context['realtime'].get('name'):
                name = context['realtime']['name']
            else:
                # æœ€åä»æ˜ å°„è¡¨è·å–
                name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
        
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤ç»“æœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary='AI åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰',
                risk_warning='è¯·é…ç½® Gemini API Key åé‡è¯•',
                success=False,
                error_message='Gemini API Key æœªé…ç½®',
            )
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥ï¼ˆåŒ…å«æŠ€æœ¯é¢æ•°æ®å’Œæ–°é—»ï¼‰
            prompt = self._format_prompt(context, name, news_context)
            
            # è·å–æ¨¡å‹åç§°
            model_name = getattr(self, '_current_model_name', 'unknown')
            
            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°é—»: {'æ˜¯' if news_context else 'å¦'}")
            
            # è®°å½•å®Œæ•´ prompt åˆ°æ—¥å¿—ï¼ˆINFOçº§åˆ«è®°å½•æ‘˜è¦ï¼ŒDEBUGè®°å½•å®Œæ•´ï¼‰
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é¢„è§ˆ]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")

            # è®¾ç½®ç”Ÿæˆé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–æ¸©åº¦å‚æ•°ï¼‰
            config = get_config()
            generation_config = {
                "temperature": config.gemini_temperature,
                "max_output_tokens": 8192,
            }

            # æ ¹æ®å®é™…ä½¿ç”¨çš„ API æ˜¾ç¤ºæ—¥å¿—
            api_provider = "OpenAI" if self._use_openai else "Gemini"
            logger.info(f"[LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ {api_provider} API...")
            
            # ä½¿ç”¨å¸¦é‡è¯•çš„ API è°ƒç”¨
            start_time = time.time()
            response_text = self._call_api_with_retry(prompt, generation_config)
            elapsed = time.time() - start_time

            # è®°å½•å“åº”ä¿¡æ¯
            logger.info(f"[LLMè¿”å›] {api_provider} API å“åº”æˆåŠŸ, è€—æ—¶ {elapsed:.2f}s, å“åº”é•¿åº¦ {len(response_text)} å­—ç¬¦")
            
            # è®°å½•å“åº”é¢„è§ˆï¼ˆINFOçº§åˆ«ï¼‰å’Œå®Œæ•´å“åº”ï¼ˆDEBUGçº§åˆ«ï¼‰
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é¢„è§ˆ]\n{response_preview}")
            logger.debug(f"=== {api_provider} å®Œæ•´å“åº” ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ===")
            
            # è§£æå“åº”
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            result.market_snapshot = self._build_market_snapshot(context)

            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è¯„åˆ† {result.sentiment_score}")
            
            return result
            
        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±è´¥: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary=f'åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)[:100]}',
                risk_warning='åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨åˆ†æ',
                success=False,
                error_message=str(e),
            )
    
    def _format_prompt(
        self, 
        context: Dict[str, Any], 
        name: str,
        news_context: Optional[str] = None
    ) -> str:
        """
        æ ¼å¼åŒ–åˆ†ææç¤ºè¯ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ v2.0ï¼‰
        
        åŒ…å«ï¼šæŠ€æœ¯æŒ‡æ ‡ã€å®æ—¶è¡Œæƒ…ï¼ˆé‡æ¯”/æ¢æ‰‹ç‡ï¼‰ã€ç­¹ç åˆ†å¸ƒã€è¶‹åŠ¿åˆ†æã€æ–°é—»
        
        Args:
            context: æŠ€æœ¯é¢æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å¢å¼ºæ•°æ®ï¼‰
            name: è‚¡ç¥¨åç§°ï¼ˆé»˜è®¤å€¼ï¼Œå¯èƒ½è¢«ä¸Šä¸‹æ–‡è¦†ç›–ï¼‰
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹
        """
        code = context.get('code', 'Unknown')
        
        # ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„è‚¡ç¥¨åç§°ï¼ˆä» realtime_quote è·å–ï¼‰
        stock_name = context.get('stock_name', name)
        if not stock_name or stock_name == f'è‚¡ç¥¨{code}':
            stock_name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
            
        today = context.get('today', {})
        
        # ========== æ„å»ºå†³ç­–ä»ªè¡¨ç›˜æ ¼å¼çš„è¾“å…¥ ==========
        prompt = f"""# å†³ç­–ä»ªè¡¨ç›˜åˆ†æè¯·æ±‚

## ğŸ“Š è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
| é¡¹ç›® | æ•°æ® |
|------|------|
| è‚¡ç¥¨ä»£ç  | **{code}** |
| è‚¡ç¥¨åç§° | **{stock_name}** |
| åˆ†ææ—¥æœŸ | {context.get('date', 'æœªçŸ¥')} |

---

## ğŸ“ˆ æŠ€æœ¯é¢æ•°æ®

### ä»Šæ—¥è¡Œæƒ…
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ”¶ç›˜ä»· | {today.get('close', 'N/A')} å…ƒ |
| å¼€ç›˜ä»· | {today.get('open', 'N/A')} å…ƒ |
| æœ€é«˜ä»· | {today.get('high', 'N/A')} å…ƒ |
| æœ€ä½ä»· | {today.get('low', 'N/A')} å…ƒ |
| æ¶¨è·Œå¹… | {today.get('pct_chg', 'N/A')}% |
| æˆäº¤é‡ | {self._format_volume(today.get('volume'))} |
| æˆäº¤é¢ | {self._format_amount(today.get('amount'))} |

### å‡çº¿ç³»ç»Ÿï¼ˆå…³é”®åˆ¤æ–­æŒ‡æ ‡ï¼‰
| å‡çº¿ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| MA5 | {today.get('ma5', 'N/A')} | çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA10 | {today.get('ma10', 'N/A')} | ä¸­çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA20 | {today.get('ma20', 'N/A')} | ä¸­æœŸè¶‹åŠ¿çº¿ |
| å‡çº¿å½¢æ€ | {context.get('ma_status', 'æœªçŸ¥')} | å¤šå¤´/ç©ºå¤´/ç¼ ç»• |
"""
        
        # æ·»åŠ å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆé‡æ¯”ã€æ¢æ‰‹ç‡ç­‰ï¼‰
        if 'realtime' in context:
            rt = context['realtime']
            prompt += f"""
### å®æ—¶è¡Œæƒ…å¢å¼ºæ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ | è§£è¯» |
|------|------|------|
| å½“å‰ä»·æ ¼ | {rt.get('price', 'N/A')} å…ƒ | |
| **é‡æ¯”** | **{rt.get('volume_ratio', 'N/A')}** | {rt.get('volume_ratio_desc', '')} |
| **æ¢æ‰‹ç‡** | **{rt.get('turnover_rate', 'N/A')}%** | |
| å¸‚ç›ˆç‡(åŠ¨æ€) | {rt.get('pe_ratio', 'N/A')} | |
| å¸‚å‡€ç‡ | {rt.get('pb_ratio', 'N/A')} | |
| æ€»å¸‚å€¼ | {self._format_amount(rt.get('total_mv'))} | |
| æµé€šå¸‚å€¼ | {self._format_amount(rt.get('circ_mv'))} | |
| 60æ—¥æ¶¨è·Œå¹… | {rt.get('change_60d', 'N/A')}% | ä¸­æœŸè¡¨ç° |
"""
        
        # æ·»åŠ ç­¹ç åˆ†å¸ƒæ•°æ®
        if 'chip' in context:
            chip = context['chip']
            profit_ratio = chip.get('profit_ratio', 0)
            prompt += f"""
### ç­¹ç åˆ†å¸ƒæ•°æ®ï¼ˆæ•ˆç‡æŒ‡æ ‡ï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·æ ‡å‡† |
|------|------|----------|
| **è·åˆ©æ¯”ä¾‹** | **{profit_ratio:.1%}** | 70-90%æ—¶è­¦æƒ• |
| å¹³å‡æˆæœ¬ | {chip.get('avg_cost', 'N/A')} å…ƒ | ç°ä»·åº”é«˜äº5-15% |
| 90%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_90', 0):.2%} | <15%ä¸ºé›†ä¸­ |
| 70%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_70', 0):.2%} | |
| ç­¹ç çŠ¶æ€ | {chip.get('chip_status', 'æœªçŸ¥')} | |
"""
        
        # æ·»åŠ è¶‹åŠ¿åˆ†æç»“æœï¼ˆåŸºäºäº¤æ˜“ç†å¿µçš„é¢„åˆ¤ï¼‰
        if 'trend_analysis' in context:
            trend = context['trend_analysis']
            bias_warning = "ğŸš¨ è¶…è¿‡5%ï¼Œä¸¥ç¦è¿½é«˜ï¼" if trend.get('bias_ma5', 0) > 5 else "âœ… å®‰å…¨èŒƒå›´"
            prompt += f"""
### è¶‹åŠ¿åˆ†æé¢„åˆ¤ï¼ˆåŸºäºäº¤æ˜“ç†å¿µï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | åˆ¤å®š |
|------|------|------|
| è¶‹åŠ¿çŠ¶æ€ | {trend.get('trend_status', 'æœªçŸ¥')} | |
| å‡çº¿æ’åˆ— | {trend.get('ma_alignment', 'æœªçŸ¥')} | MA5>MA10>MA20ä¸ºå¤šå¤´ |
| è¶‹åŠ¿å¼ºåº¦ | {trend.get('trend_strength', 0)}/100 | |
| **ä¹–ç¦»ç‡(MA5)** | **{trend.get('bias_ma5', 0):+.2f}%** | {bias_warning} |
| ä¹–ç¦»ç‡(MA10) | {trend.get('bias_ma10', 0):+.2f}% | |
| é‡èƒ½çŠ¶æ€ | {trend.get('volume_status', 'æœªçŸ¥')} | {trend.get('volume_trend', '')} |
| ç³»ç»Ÿä¿¡å· | {trend.get('buy_signal', 'æœªçŸ¥')} | |
| ç³»ç»Ÿè¯„åˆ† | {trend.get('signal_score', 0)}/100 | |

#### ç³»ç»Ÿåˆ†æç†ç”±
**ä¹°å…¥ç†ç”±**ï¼š
{chr(10).join('- ' + r for r in trend.get('signal_reasons', ['æ— '])) if trend.get('signal_reasons') else '- æ— '}

**é£é™©å› ç´ **ï¼š
{chr(10).join('- ' + r for r in trend.get('risk_factors', ['æ— '])) if trend.get('risk_factors') else '- æ— '}
"""
        
        # æ·»åŠ æ˜¨æ—¥å¯¹æ¯”æ•°æ®
        if 'yesterday' in context:
            volume_change = context.get('volume_change_ratio', 'N/A')
            prompt += f"""
### é‡ä»·å˜åŒ–
- æˆäº¤é‡è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{volume_change}å€
- ä»·æ ¼è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{context.get('price_change_ratio', 'N/A')}%
"""
        
        # æ·»åŠ æ–°é—»æœç´¢ç»“æœï¼ˆé‡ç‚¹åŒºåŸŸï¼‰
        prompt += """
---

## ğŸ“° èˆ†æƒ…æƒ…æŠ¥
"""
        if news_context:
            prompt += f"""
ä»¥ä¸‹æ˜¯ **{stock_name}({code})** è¿‘7æ—¥çš„æ–°é—»æœç´¢ç»“æœï¼Œè¯·é‡ç‚¹æå–ï¼š
1. ğŸš¨ **é£é™©è­¦æŠ¥**ï¼šå‡æŒã€å¤„ç½šã€åˆ©ç©º
2. ğŸ¯ **åˆ©å¥½å‚¬åŒ–**ï¼šä¸šç»©ã€åˆåŒã€æ”¿ç­–
3. ğŸ“Š **ä¸šç»©é¢„æœŸ**ï¼šå¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥

```
{news_context}
```
"""
        else:
            prompt += """
æœªæœç´¢åˆ°è¯¥è‚¡ç¥¨è¿‘æœŸçš„ç›¸å…³æ–°é—»ã€‚è¯·ä¸»è¦ä¾æ®æŠ€æœ¯é¢æ•°æ®è¿›è¡Œåˆ†æã€‚
"""

        # æ³¨å…¥ç¼ºå¤±æ•°æ®è­¦å‘Š
        if context.get('data_missing'):
            prompt += """
âš ï¸ **æ•°æ®ç¼ºå¤±è­¦å‘Š**
ç”±äºæ¥å£é™åˆ¶ï¼Œå½“å‰æ— æ³•è·å–å®Œæ•´çš„å®æ—¶è¡Œæƒ…å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®ã€‚
è¯· **å¿½ç•¥ä¸Šè¿°è¡¨æ ¼ä¸­çš„ N/A æ•°æ®**ï¼Œé‡ç‚¹ä¾æ® **ã€ğŸ“° èˆ†æƒ…æƒ…æŠ¥ã€‘** ä¸­çš„æ–°é—»è¿›è¡ŒåŸºæœ¬é¢å’Œæƒ…ç»ªé¢åˆ†æã€‚
åœ¨å›ç­”æŠ€æœ¯é¢é—®é¢˜ï¼ˆå¦‚å‡çº¿ã€ä¹–ç¦»ç‡ï¼‰æ—¶ï¼Œè¯·ç›´æ¥è¯´æ˜â€œæ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­â€ï¼Œ**ä¸¥ç¦ç¼–é€ æ•°æ®**ã€‚
"""

        # æ˜ç¡®çš„è¾“å‡ºè¦æ±‚
        prompt += f"""
---

## âœ… åˆ†æä»»åŠ¡

è¯·ä¸º **{stock_name}({code})** ç”Ÿæˆã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼Œä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºã€‚

### âš ï¸ é‡è¦ï¼šè‚¡ç¥¨åç§°ç¡®è®¤
å¦‚æœä¸Šæ–¹æ˜¾ç¤ºçš„è‚¡ç¥¨åç§°ä¸º"è‚¡ç¥¨{code}"æˆ–ä¸æ­£ç¡®ï¼Œè¯·åœ¨åˆ†æå¼€å¤´**æ˜ç¡®è¾“å‡ºè¯¥è‚¡ç¥¨çš„æ­£ç¡®ä¸­æ–‡å…¨ç§°**ã€‚

### é‡ç‚¹å…³æ³¨ï¼ˆå¿…é¡»æ˜ç¡®å›ç­”ï¼‰ï¼š
1. â“ æ˜¯å¦æ»¡è¶³ MA5>MA10>MA20 å¤šå¤´æ’åˆ—ï¼Ÿ
2. â“ å½“å‰ä¹–ç¦»ç‡æ˜¯å¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆ<5%ï¼‰ï¼Ÿâ€”â€” è¶…è¿‡5%å¿…é¡»æ ‡æ³¨"ä¸¥ç¦è¿½é«˜"
3. â“ é‡èƒ½æ˜¯å¦é…åˆï¼ˆç¼©é‡å›è°ƒ/æ”¾é‡çªç ´ï¼‰ï¼Ÿ
4. â“ ç­¹ç ç»“æ„æ˜¯å¦å¥åº·ï¼Ÿ
5. â“ æ¶ˆæ¯é¢æœ‰æ— é‡å¤§åˆ©ç©ºï¼Ÿï¼ˆå‡æŒã€å¤„ç½šã€ä¸šç»©å˜è„¸ç­‰ï¼‰

### å†³ç­–ä»ªè¡¨ç›˜è¦æ±‚ï¼š
- **è‚¡ç¥¨åç§°**ï¼šå¿…é¡»è¾“å‡ºæ­£ç¡®çš„ä¸­æ–‡å…¨ç§°ï¼ˆå¦‚"è´µå·èŒ…å°"è€Œé"è‚¡ç¥¨600519"ï¼‰
- **æ ¸å¿ƒç»“è®º**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°/è¯¥å–/è¯¥ç­‰
- **æŒä»“åˆ†ç±»å»ºè®®**ï¼šç©ºä»“è€…æ€ä¹ˆåš vs æŒä»“è€…æ€ä¹ˆåš
- **å…·ä½“ç‹™å‡»ç‚¹ä½**ï¼šä¹°å…¥ä»·ã€æ­¢æŸä»·ã€ç›®æ ‡ä»·ï¼ˆç²¾ç¡®åˆ°åˆ†ï¼‰
- **æ£€æŸ¥æ¸…å•**ï¼šæ¯é¡¹ç”¨ âœ…/âš ï¸/âŒ æ ‡è®°

è¯·è¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼å†³ç­–ä»ªè¡¨ç›˜ã€‚"""
        
        return prompt
    
    def _format_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡æ˜¾ç¤º"""
        if volume is None:
            return 'N/A'
        if volume >= 1e8:
            return f"{volume / 1e8:.2f} äº¿è‚¡"
        elif volume >= 1e4:
            return f"{volume / 1e4:.2f} ä¸‡è‚¡"
        else:
            return f"{volume:.0f} è‚¡"
    
    def _format_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¢æ˜¾ç¤º"""
        if amount is None:
            return 'N/A'
        if amount >= 1e8:
            return f"{amount / 1e8:.2f} äº¿å…ƒ"
        elif amount >= 1e4:
            return f"{amount / 1e4:.2f} ä¸‡å…ƒ"
        else:
            return f"{amount:.0f} å…ƒ"

    def _format_percent(self, value: Optional[float]) -> str:
        """æ ¼å¼åŒ–ç™¾åˆ†æ¯”æ˜¾ç¤º"""
        if value is None:
            return 'N/A'
        try:
            return f"{float(value):.2f}%"
        except (TypeError, ValueError):
            return 'N/A'

    def _format_price(self, value: Optional[float]) -> str:
        """æ ¼å¼åŒ–ä»·æ ¼æ˜¾ç¤º"""
        if value is None:
            return 'N/A'
        try:
            return f"{float(value):.2f}"
        except (TypeError, ValueError):
            return 'N/A'

    def _build_market_snapshot(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå½“æ—¥è¡Œæƒ…å¿«ç…§ï¼ˆå±•ç¤ºç”¨ï¼‰"""
        today = context.get('today', {}) or {}
        realtime = context.get('realtime', {}) or {}
        yesterday = context.get('yesterday', {}) or {}

        prev_close = yesterday.get('close')
        close = today.get('close')
        high = today.get('high')
        low = today.get('low')

        amplitude = None
        change_amount = None
        if prev_close not in (None, 0) and high is not None and low is not None:
            try:
                amplitude = (float(high) - float(low)) / float(prev_close) * 100
            except (TypeError, ValueError, ZeroDivisionError):
                amplitude = None
        if prev_close is not None and close is not None:
            try:
                change_amount = float(close) - float(prev_close)
            except (TypeError, ValueError):
                change_amount = None

        snapshot = {
            "date": context.get('date', 'æœªçŸ¥'),
            "close": self._format_price(close),
            "open": self._format_price(today.get('open')),
            "high": self._format_price(high),
            "low": self._format_price(low),
            "prev_close": self._format_price(prev_close),
            "pct_chg": self._format_percent(today.get('pct_chg')),
            "change_amount": self._format_price(change_amount),
            "amplitude": self._format_percent(amplitude),
            "volume": self._format_volume(today.get('volume')),
            "amount": self._format_amount(today.get('amount')),
        }

        if realtime:
            snapshot.update({
                "price": self._format_price(realtime.get('price')),
                "volume_ratio": realtime.get('volume_ratio', 'N/A'),
                "turnover_rate": self._format_percent(realtime.get('turnover_rate')),
                "source": getattr(realtime.get('source'), 'value', realtime.get('source', 'N/A')),
            })

        return snapshot
    
    def identify_market(self, code: str) -> str:
        """
        Identifies market type based on stock code format.
        Returns: 'CN', 'US', 'HK', 'CRYPTO', or 'UNKNOWN'
        """
        code = code.upper().strip()
        
        # 1. Crypto: Often contains USDT, BUSD, USD or is BTC/ETH
        if 'USDT' in code or 'BUSD' in code or code in ['BTC', 'ETH']:
            return 'CRYPTO'
            
        # 2. China A-Shares (CN)
        # Common formats: 60xxxx, 00xxxx, 30xxxx (6 digits)
        # Or suffix: .SS (Shanghai), .SZ (Shenzhen)
        if code.endswith(('.SS', '.SZ')):
            return 'CN'
        if re.match(r'^(60|00|30|68)\d{4}$', code):
            return 'CN'
            
        # 3. Hong Kong (HK)
        # Common formats: 00700, 09988 (5 digits), sometimes suffix .HK
        if code.endswith('.HK'):
            return 'HK'
        if re.match(r'^\d{5}$', code):
            return 'HK'
            
        # 4. US Stocks
        # Usually just letters (AAPL, TSLA) or suffix .US
        # Sometimes containing dots (BRK.B)
        if code.endswith('.US'):
            return 'US'
        if re.match(r'^[A-Z\.]+$', code): # Pure letters
            return 'US'
            
        # Default
        return 'UNKNOWN'

    def _parse_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
        ) -> AnalysisResult:
            """
            è§£æ Gemini å“åº”ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ç‰ˆï¼‰ - å®Œæ•´ä¿®å¤ç‰ˆ
            
            æ”¹è¿›ç‚¹ï¼š
            1. ä¿®å¤äº†é€»è¾‘è¦†ç›– Bugï¼šé£æ§æ‹¦æˆªç°åœ¨æ‹¥æœ‰æœ€é«˜ä¼˜å…ˆçº§ã€‚
            2. å¢å¼ºäº† JSON è§£æçš„é²æ£’æ€§ï¼šé˜²æ­¢ int() è½¬æ¢å¤±è´¥æˆ–å­—å…¸é”®ç¼ºå¤±å¯¼è‡´å´©æºƒã€‚
            3. è¯­ä¹‰ä¿®æ­£ï¼šä½¿ç”¨ "ç¦»åœºå›é¿" ä»£æ›¿å•çº¯çš„ "æ¸…ä»“"ï¼Œé€‚åº”ä¸åŒæŒä»“çŠ¶æ€ã€‚
            4. UI å…œåº•ï¼šå¼ºåˆ¶ä¿®å¤ Dashboard æ˜¾ç¤ºï¼Œç¡®ä¿é£é™©æç¤ºä¸€å®šä¼šè¢«ç”¨æˆ·çœ‹åˆ°ã€‚
            """
            try:
                # =================================================
                # 1. æ–‡æœ¬æ¸…ç†ä¸ JSON æå–
                # =================================================

                cleaned_text = response_text
                if '```json' in cleaned_text:
                    cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
                elif '```' in cleaned_text:
                    cleaned_text = cleaned_text.replace('```', '')
                
                # å°è¯•æ‰¾åˆ° JSON å†…å®¹
                json_start = cleaned_text.find('{')
                json_end = cleaned_text.rfind('}') + 1
                
                if json_start >= 0 and json_end > json_start:
                    json_str = cleaned_text[json_start:json_end]
                    # å°è¯•ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é”™è¯¯
                    json_str = self._fix_json_string(json_str)
                    data = json.loads(json_str)

                    # =================================================
                    # 2. æ ¸å¿ƒæ•°æ®å®‰å…¨æå– (Safe Extraction)
                    # =================================================

                    # --- æå–æƒ…ç»ªåˆ† (å¸¦ç±»å‹å®‰å…¨è½¬æ¢) ---
                    try:
                        sentiment_score = int(float(data.get('sentiment_score', 50)))
                    except (ValueError, TypeError):
                        sentiment_score = 50

                    # --- æå– Dashboard åŠå­æ¨¡å— ---
                    dashboard = data.get('dashboard', {})
                    if not isinstance(dashboard, dict): dashboard = {}
                    
                    data_perspective = dashboard.get('data_perspective', {})
                    if not isinstance(data_perspective, dict): data_perspective = {}

                    intelligence = dashboard.get('intelligence', {})
                    if not isinstance(intelligence, dict): intelligence = {}

                    # =================================================
                    # 3. äº¤æ˜“æƒé™é—¨æ§›è®¡ç®— (Trade Permission Gates)
                    # =================================================

                    # ğŸ›‘ é—¨æ§› A: è¶‹åŠ¿ç¡¬æ­¢æŸ (Trend Hard Stop)
                    trend_status = data_perspective.get('trend_status', {})
                    try:
                        trend_score = int(float(trend_status.get('trend_score', 50)))
                    except (ValueError, TypeError):
                        trend_score = 50
                    
                    # å®šä¹‰ï¼šè¶‹åŠ¿ç ´å = åˆ†æ•°ä½äº 40
                    trend_broken = trend_score < 40

                    # ğŸš§ é—¨æ§› B: ç¯å¢ƒè¿‡æ»¤å™¨ (Context Filters)
                    # 1. æƒ…ç»ªè¿‡æ»¤å™¨
                    sentiment_ok = sentiment_score >= 60

                    # 2. ä¹–ç¦»ç‡è¿‡æ»¤å™¨
                    price_position = data_perspective.get('price_position', {})
                    bias_status = price_position.get('bias_status', '')
                    bias_ok = bias_status not in ['å±é™©', 'ç¦æ­¢']

                    # 3. æ—¶é—´é£é™©è¿‡æ»¤å™¨
                    risk_alerts = intelligence.get('risk_alerts', [])
                    if not isinstance(risk_alerts, list): risk_alerts = []
                    
                    risk_warning_text = data.get('risk_warning', '')

                    current_market = self.identify_market(code) # e.g., 'US' or 'CN'

                    time_risk_reasons = []
                    
                    # æ‹¼æ¥æ‰€æœ‰é£é™©æ–‡æœ¬è¿›è¡Œå…³é”®è¯æ£€ç´¢
                    risk_text_pool = str(risk_warning_text) + " " + " ".join([str(x) for x in risk_alerts])

                    # æ£€æŸ¥å…¨å±€å˜é‡æ˜¯å¦å­˜åœ¨ï¼Œé˜²æ­¢æŠ¥é”™
                    for event_key, event_data in TIME_RISK_EVENTS.items():
                    
                        # --- CHECK: Is this risk relevant to my market? ---
                        target_markets = event_data.get("target_markets", ["ALL"])
                        
                        is_relevant = (
                            "ALL" in target_markets or 
                            current_market == 'UNKNOWN' or 
                            current_market in target_markets
                        )
                        
                        if not is_relevant:
                            continue # Skip unrelated risks (e.g. don't check LPR for Apple)

                        # --- CHECK: Do keywords exist? ---
                        # We use 'keywords' from the dictionary to scan the AI's text
                        if any(kw in risk_text_pool for kw in event_data["keywords"]):
                            # Formatting the reason to be specific
                            prefix = f"[{current_market} Market Risk]" if current_market != 'UNKNOWN' else ""
                            time_risk_reasons.append(f"{prefix} {event_data['reason']}")
                    
                    # =================================================
                    # 4. å†³ç­–é€»è¾‘åˆ†å±‚ (Decision Hierarchy)
                    # ä¼˜å…ˆçº§ï¼šè¶‹åŠ¿ç ´å(å–) > ç¯å¢ƒé£é™©(è§‚æœ›) > AIåŸå§‹å»ºè®®
                    # =================================================
                    
                    final_decision_type = ''
                    final_operation_advice = ''
                    final_confidence = ''
                    block_reasons = []
                    ALLOW_TRADE = True # é»˜è®¤ä¸ºçœŸï¼Œä¸‹é¢é€æ­¥è¯ä¼ª

                    # æ”¶é›†é˜»æ–­åŸå› 
                    if not sentiment_ok:
                        block_reasons.append(f"å¸‚åœºæƒ…ç»ªåå¼±({sentiment_score})")
                    if not bias_ok:
                        block_reasons.append(f"ä¹–ç¦»ç‡å¤„äº{bias_status}åŒº")
                    if time_risk_reasons:
                        block_reasons.extend(time_risk_reasons)

                    # --- æ ¸å¿ƒåˆ¤å®šè·¯å¾„ ---
                    
                    if trend_broken:
                        # ğŸ”´ è·¯å¾„ 1: è¶‹åŠ¿å·²å -> å¼ºåˆ¶å–å‡º/å›é¿
                        final_operation_advice = 'å–å‡º'
                        final_decision_type = 'sell'
                        final_confidence = 'é«˜'
                        # æ’å…¥æœ€å…³é”®çš„åŸå› åˆ°åˆ—è¡¨å¤´éƒ¨
                        block_reasons.insert(0, f"è¶‹åŠ¿ç»“æ„ç ´å(è¯„åˆ†{trend_score})")
                        ALLOW_TRADE = False 

                    elif block_reasons:
                        # ğŸŸ¡ è·¯å¾„ 2: è¶‹åŠ¿å°šå¯ï¼Œä½†ç¯å¢ƒæœ‰é£é™© -> å¼ºåˆ¶è§‚æœ›/ç¦æ­¢ä¹°å…¥
                        ai_advice = data.get('operation_advice', 'æŒæœ‰')
                        
                        # ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœ AI æœ¬èº«å°±å»ºè®®å–å‡ºï¼Œæˆ‘ä»¬å°Šé‡å–å‡ºå»ºè®®
                        if ai_advice in ['å–å‡º', 'å‡ä»“', 'å¼ºçƒˆå–å‡º']:
                            final_operation_advice = ai_advice
                            final_decision_type = 'sell'
                            final_confidence = data.get('confidence_level', 'é«˜')
                        else:
                            # å¦‚æœ AI æƒ³ä¹°å…¥æˆ–æŒæœ‰ï¼Œç”±äºç¯å¢ƒé£é™©ï¼Œå¼ºåˆ¶è½¬ä¸ºè§‚æœ›
                            final_operation_advice = 'è§‚æœ›'
                            final_decision_type = 'hold'
                            final_confidence = 'ä½'
                        
                        ALLOW_TRADE = False

                    else:
                        # ğŸŸ¢ è·¯å¾„ 3: ä¸€åˆ‡æ­£å¸¸ -> å®Œå…¨é‡‡çº³ AI å»ºè®®
                        final_operation_advice = data.get('operation_advice', 'æŒæœ‰')
                        final_decision_type = data.get('decision_type', '') 
                        final_confidence = data.get('confidence_level', 'ä¸­')
                        ALLOW_TRADE = True

                    # --- è¡¥å…¨ decision_type (å¦‚æœ AI æ¼äº†) ---
                    if not final_decision_type:
                        if final_operation_advice in ['ä¹°å…¥', 'åŠ ä»“', 'å¼ºçƒˆä¹°å…¥']:
                            final_decision_type = 'buy'
                        elif final_operation_advice in ['å–å‡º', 'å‡ä»“', 'å¼ºçƒˆå–å‡º']:
                            final_decision_type = 'sell'
                        else:
                            final_decision_type = 'hold'

                    # =================================================
                    # 5. æ•°æ®ä¿®æ­£ä¸å›å†™ (Data Correction & Write-back)
                    # =================================================

                    # 1. ä¿®æ­£è‚¡ç¥¨åç§° (ä¼˜å…ˆä½¿ç”¨ AI è¯†åˆ«çš„å‡†ç¡®åç§°)
                    ai_stock_name = data.get('stock_name')
                    if ai_stock_name and (name.startswith('è‚¡ç¥¨') or name == code or 'Unknown' in name):
                        name = ai_stock_name

                    # 2. ä¿®æ­£ Dashboard æ ¸å¿ƒç»“è®º (ç¡®ä¿é£é™©è¢«çœ‹è§)
                    # å¦‚æœ Dashboard å­˜åœ¨ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿ core_conclusion åæ˜ äº†æˆ‘ä»¬çš„å¼ºåˆ¶é£æ§é€»è¾‘
                    if dashboard:
                        # ç¡®ä¿ core_conclusion å­—å…¸å­˜åœ¨
                        if 'core_conclusion' not in dashboard or not isinstance(dashboard['core_conclusion'], dict):
                            dashboard['core_conclusion'] = {
                                'signal_type': 'âšªåˆ†æä¸­',
                                'one_sentence': 'æ•°æ®æ­£åœ¨æ•´åˆ...',
                                'confidence_score': 50
                            }
                        
                        core = dashboard['core_conclusion']

                        # --- åœºæ™¯ A: è§¦å‘â€œè¶‹åŠ¿ç ´åâ€ (ç¡¬æ­¢æŸ) ---
                        if trend_broken:
                            core['signal_type'] = 'ğŸ”´ç¦»åœºå›é¿'  # ä½¿ç”¨ä¸­æ€§åç©ºçš„è¯æ±‡ï¼Œé€‚ç”¨æ‰€æœ‰äººç¾¤
                            core['one_sentence'] = f"è¶‹åŠ¿è¯„åˆ†è¿‡ä½ ({trend_score}åˆ†)ï¼Œå¤šå¤´ç»“æ„å·²ç ´åï¼Œå»ºè®®ç«‹å³ç¦»åœºæˆ–åœæ­¢ä¹°å…¥ã€‚"
                            core['time_sensitivity'] = 'ç´§æ€¥'
                            core['block_reason'] = f"è¶‹åŠ¿ç¡¬æ­¢æŸè§¦å‘ (è¯„åˆ† {trend_score} < 40)"
                            # å¼ºåˆ¶æ›´æ–° dashboard ä¸­çš„å»ºè®®
                            core['suggestion'] = 'å–å‡º/å›é¿'
                        
                        # --- åœºæ™¯ B: è§¦å‘â€œç¯å¢ƒé£æ§â€ (è½¯è¿‡æ»¤) ---
                        elif not ALLOW_TRADE and final_decision_type != 'sell':
                            core['signal_type'] = 'ğŸŸ¡æš‚ç¼“ä»‹å…¥'
                            # ä¿ç•™ AI åŸè¯ï¼Œä½†åŠ ä¸Šå‰ç¼€è­¦å‘Š
                            orig_sentence = core.get('one_sentence', '')
                            core['one_sentence'] = f"ã€ç¯å¢ƒé£é™©ã€‘å½“å‰èƒœç‡ä¸é«˜ï¼Œå»ºè®®è§‚æœ›ã€‚({orig_sentence})"
                            core['time_sensitivity'] = 'ä¸æ€¥'
                            core['block_reason'] = "; ".join(block_reasons)

                    # 3. ç”Ÿæˆæœ€ç»ˆçš„ Risk Warning æ–‡æœ¬
                    full_risk_warning = data.get('risk_warning', '')
                    if block_reasons:
                        # å°†é£æ§æ‹¦æˆªåŸå› åŠ åˆ°æœ€å‰é¢
                        full_risk_warning = f"ã€é£æ§æ‹¦æˆªã€‘{'; '.join(block_reasons)} | " + full_risk_warning

                    # =================================================
                    # 6. è¿”å›ç»“æœå¯¹è±¡
                    # =================================================
                    return AnalysisResult(
                        code=code,
                        name=name,
                        # æ ¸å¿ƒæŒ‡æ ‡ (ä½¿ç”¨è®¡ç®—åçš„æœ€ç»ˆå€¼)
                        sentiment_score=sentiment_score,
                        trend_prediction=data.get('trend_prediction', 'éœ‡è¡'),
                        operation_advice=final_operation_advice,
                        decision_type=final_decision_type,
                        confidence_level=final_confidence,
                        # å†³ç­–ä»ªè¡¨ç›˜
                        dashboard=dashboard,
                        # åŸå§‹åˆ†ææ•°æ®é€ä¼ 
                        trend_analysis=data.get('trend_analysis', ''),
                        short_term_outlook=data.get('short_term_outlook', ''),
                        medium_term_outlook=data.get('medium_term_outlook', ''),
                        technical_analysis=data.get('technical_analysis', ''),
                        ma_analysis=data.get('ma_analysis', ''),
                        volume_analysis=data.get('volume_analysis', ''),
                        pattern_analysis=data.get('pattern_analysis', ''),
                        fundamental_analysis=data.get('fundamental_analysis', ''),
                        sector_position=data.get('sector_position', ''),
                        company_highlights=data.get('company_highlights', ''),
                        news_summary=data.get('news_summary', ''),
                        market_sentiment=data.get('market_sentiment', ''),
                        hot_topics=data.get('hot_topics', ''),
                        # ç»¼åˆ
                        analysis_summary=data.get('analysis_summary', 'åˆ†æå®Œæˆ'),
                        key_points=data.get('key_points', ''),
                        risk_warning=full_risk_warning,
                        buy_reason=data.get('buy_reason', ''),
                        # å…ƒæ•°æ®
                        search_performed=data.get('search_performed', False),
                        data_sources=data.get('data_sources', 'æŠ€æœ¯é¢æ•°æ®'),
                        success=True,
                    )
                else:
                    # æ²¡æ‰¾åˆ° JSON
                    logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå– JSONï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬åˆ†æ")
                    return self._parse_text_response(response_text, code, name)
                    
            except json.JSONDecodeError as e:
                logger.warning(f"JSON è§£æå¤±è´¥: {e}ï¼Œå°è¯•ä»æ–‡æœ¬æå–")
                return self._parse_text_response(response_text, code, name)
            except Exception as e:
                logger.error(f"è§£æè¿‡ç¨‹å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                # å‘ç”ŸæœªçŸ¥é”™è¯¯æ—¶å…œåº•
                return self._parse_text_response(response_text, code, name)
    
    def _fix_json_string(self, json_str: str) -> str:
        """ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜"""
        import re
        
        # ç§»é™¤æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å°¾éšé€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å¸ƒå°”å€¼æ˜¯å°å†™
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        # fix by json-repair
        json_str = repair_json(json_str)
        
        return json_str
    
    def _parse_text_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """ä»çº¯æ–‡æœ¬å“åº”ä¸­å°½å¯èƒ½æå–åˆ†æä¿¡æ¯"""
        # å°è¯•è¯†åˆ«å…³é”®è¯æ¥åˆ¤æ–­æƒ…ç»ª
        sentiment_score = 50
        trend = 'éœ‡è¡'
        advice = 'æŒæœ‰'
        
        text_lower = response_text.lower()
        
        # ç®€å•çš„æƒ…ç»ªè¯†åˆ«
        positive_keywords = ['çœ‹å¤š', 'ä¹°å…¥', 'ä¸Šæ¶¨', 'çªç ´', 'å¼ºåŠ¿', 'åˆ©å¥½', 'åŠ ä»“', 'bullish', 'buy']
        negative_keywords = ['çœ‹ç©º', 'å–å‡º', 'ä¸‹è·Œ', 'è·Œç ´', 'å¼±åŠ¿', 'åˆ©ç©º', 'å‡ä»“', 'bearish', 'sell']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text_lower)
        negative_count = sum(1 for kw in negative_keywords if kw in text_lower)
        
        if positive_count > negative_count + 1:
            sentiment_score = 65
            trend = 'çœ‹å¤š'
            advice = 'ä¹°å…¥'
            decision_type = 'buy'
        elif negative_count > positive_count + 1:
            sentiment_score = 35
            trend = 'çœ‹ç©º'
            advice = 'å–å‡º'
            decision_type = 'sell'
        else:
            decision_type = 'hold'
        
        # æˆªå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        summary = response_text[:500] if response_text else 'æ— åˆ†æç»“æœ'
        
        return AnalysisResult(
            code=code,
            name=name,
            sentiment_score=sentiment_score,
            trend_prediction=trend,
            operation_advice=advice,
            decision_type=decision_type,
            confidence_level='ä½',
            analysis_summary=summary,
            key_points='JSONè§£æå¤±è´¥ï¼Œä»…ä¾›å‚è€ƒ',
            risk_warning='åˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®ï¼Œå»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯åˆ¤æ–­',
            raw_response=response_text,
            success=True,
        )
    
    def batch_analyze(
        self, 
        contexts: List[Dict[str, Any]],
        delay_between: float = 2.0
    ) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨
        
        æ³¨æ„ï¼šä¸ºé¿å… API é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡åˆ†æä¹‹é—´ä¼šæœ‰å»¶è¿Ÿ
        
        Args:
            contexts: ä¸Šä¸‹æ–‡æ•°æ®åˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
            
        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []
        
        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’åç»§ç»­...")
                time.sleep(delay_between)
            
            result = self.analyze(context)
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•°
def get_analyzer() -> GeminiAnalyzer:
    """è·å– Gemini åˆ†æå™¨å®ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ•°æ®
    test_context = {
        'code': '600519',
        'date': '2026-01-09',
        'today': {
            'open': 1800.0,
            'high': 1850.0,
            'low': 1780.0,
            'close': 1820.0,
            'volume': 10000000,
            'amount': 18200000000,
            'pct_chg': 1.5,
            'ma5': 1810.0,
            'ma10': 1800.0,
            'ma20': 1790.0,
            'volume_ratio': 1.2,
        },
        'ma_status': 'å¤šå¤´æ’åˆ— ğŸ“ˆ',
        'volume_change_ratio': 1.3,
        'price_change_ratio': 1.5,
    }
    
    analyzer = GeminiAnalyzer()
    
    if analyzer.is_available():
        print("=== AI åˆ†ææµ‹è¯• ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æç»“æœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
